# Virtual Online Drum Kit App (VODKA)

Transform any surface into a drum kit using computer vision and accelerometer data!

## System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Drumstick  â”‚
â”‚ ESP32+MPU   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ USB
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python Backend  â”‚â†â”€â”€â”€â”€â†’â”‚  Webcam    â”‚
â”‚  - Hit Detection â”‚      â”‚  (CV)      â”‚
â”‚  - Sound Engine  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ WebSocket
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚
â”‚  - Visualization â”‚
â”‚  - Controls      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### 1. Hardware Setup
See `firmware/esp32_sensor/README.md`

### 2. Backend Setup
```bash
cd backend
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your configuration
python app.py
```

### 3. Frontend Setup
```bash
cd frontend
npm install
npm run dev
```

### 4. Upload Firmware
Open `firmware/esp32_sensor/esp32_sensor.ino` in Arduino IDE and upload to ESP32.

## Project Structure
```
virtual-drum-kit/
â”œâ”€â”€ firmware/           # ESP32 code
â”œâ”€â”€ backend/           # Python Flask server
â”‚   â”œâ”€â”€ services/      # Core logic modules
â”‚   â”œâ”€â”€ utils/         # Helper functions
â”‚   â””â”€â”€ app.py         # Main server
â”œâ”€â”€ frontend/          # React web app
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/
â”‚       â””â”€â”€ services/
â”œâ”€â”€ sounds/            # Audio samples
â”œâ”€â”€ config/            # Configuration files
â””â”€â”€ docs/              # Documentation
```

## Team Roles

- **Person 1:** Hardware + Sensor Integration
- **Person 2:** Computer Vision + ML
- **Person 3:** Web UI + Sound Engine

## Model Integration - YOLO/FastSAM

### ğŸš€ Quick Start: Test Locally (No Deployment)

Open http://localhost:5173 in your browser and click "Start Streaming".

### Model Options

**Option 1: Local YOLO (Development)**
```bash
pip install ultralytics
python app.py
```
- âœ… No deployment needed
- âœ… Real segmentation
- âœ… Fast iteration

**Option 2: Baseten (Production)**
```bash
# Deploy your model to Baseten
# Update .env with endpoint
python app.py
```
- âœ… GPU acceleration
- âœ… Scalable
- âœ… Production ready

### Architecture

- Webcam captures frames at 10fps
- Frame buffer keeps last 2 seconds
- Calibration runs: once, 2s after clicking "Start Streaming"
- Segments stored in memory for hit localization
- Hits map to nearest segment â†’ drum pad

## Testing

### Hit Mapping & Segmentation Store Test
```bash
cd backend
python3 test/test_hit_mapping.py
```

Verifies:
- Segmentation store saves/retrieves segments
- Hit localizer maps coordinates to objects
- Object class names are properly associated

### Simulate Hits via Browser Console
```javascript
socketService.emit('simulate_hit', {
  intensity: 500,
  timestamp: Date.now()
});
```

## Troubleshooting

### ESP32 not detected
- Check USB cable (must support data transfer)
- Install CH340 drivers if needed
- Try different USB port

### No sound playing
- Check `sounds/` directory has .wav files
- Verify pygame.mixer initialized correctly
- Check system audio isn't muted

### High latency
- Reduce webcam resolution
- Disable CV and use accelerometer only
- Check network latency if using hosted model
EOF